{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking pour une seule prédiction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Author Colin de Seroux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Installation des dépendances</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Importation des dépendances</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from utils import extract_annotations_from_file, extract_predictions_from_file, evaluate_metrics, display_metrics, prepare_confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Code principale</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightgreen\">Environnement</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_FILE_PATH = \"../data/dataset4/test/result.json\"\n",
    "PREDICTIONS_FILE_PATH = \"../results/predictions/predictions_hailo8l_yolov8n_trained.hef.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightgreen\">Récupération des données</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, class_names = extract_annotations_from_file(ANNOTATIONS_FILE_PATH)\n",
    "coco = COCO(ANNOTATIONS_FILE_PATH)\n",
    "y_pred, y_scores = extract_predictions_from_file(coco, PREDICTIONS_FILE_PATH)\n",
    "coco_annotations = COCO(ANNOTATIONS_FILE_PATH)\n",
    "coco_predictions = coco_annotations.loadRes(PREDICTIONS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightgreen\">mAP</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialiser l'évaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_eval = COCOeval(coco_annotations, coco_predictions, iouType=\"bbox\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer le mAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightgreen\">F1 Score</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, scores, iou_lookup = evaluate_metrics(coco_eval)\n",
    "display_metrics(precision, recall, iou_lookup, None)\n",
    "\n",
    "# TODO des corrections restent à faire\n",
    "# for cat in coco_annotations.loadCats(coco_annotations.getCatIds()):\n",
    "#         coco_eval.params.catIds = [cat[\"id\"]]\n",
    "#         precision, recall, scores, iou_lookup = evaluate_metrics(coco_eval)\n",
    "#         display_metrics(precision, recall, iou_lookup, class_name=cat[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightgreen\">Matrice de confusion</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préparation des données pour la matrice de confusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_flat, y_pred_flat, classes = prepare_confusion_matrix(y_true, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout d'une classe 'background' lorsque rien n'est détecté.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names.append(\"background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul de la matrice de confusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true_flat, y_pred_flat, labels=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher la matrice de confusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, \"d\", class_names, \"Matrice de confusion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher la matrice de confusion normalisée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_normalized = cm.astype(\"float\") / (cm.sum(axis=1)[:, np.newaxis] + 1e-8)\n",
    "\n",
    "plot_confusion_matrix(cm_normalized, \".2f\", class_names, \"Matrice de confusion normalisée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue\">Sources</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://gist.github.com/shivamsnaik/c5c5e99c00819d2167317b1e56871187\n",
    "- https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.f1_score.html\n",
    "- https://kobia.fr/classification-metrics-f1-score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_developpement_application_IA_embarquee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
